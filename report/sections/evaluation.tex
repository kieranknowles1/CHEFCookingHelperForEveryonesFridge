\todoinline{
    Evaluation
    You should present two or three critical evaluations of your work, in separate sections or chapters.

    •	Discussion and evaluation of findings
    If you have conducted an investigation into a research question or hypothesis, this is where you discuss the meaning of your results.
    What answers have you found to the question that you are investigating? You should explicitly relate your findings to the problem, question or hypothesis,
    and discuss how far you have answered that question or solved the problem, whether your results support or refute your hypotheses, etc. You may wish to
    compare your findings with those of other work that you have discussed in your literature review. The marking scheme asks you do discuss your confidence in
    your findings and how far they can be generalised. Are there factors that affect the reliability of your results or conclusions? If this is relevant to your project,
    are your results statistically significant? Would you expect similar studies to achieve the same results? Would you expect that people carrying out similar work in
    a different organisation would come to similar conclusions? Remember that it is often not possible to generalise from a single case,
    or from a small number of tests participants etc.

    •	An evaluation of your product
    If you have built a product, you should evaluate your product from a technical point of view. You need to identify the strengths and weaknesses of your product
    in meeting its requirements, and review the possible alternative technical approaches to its design and implementation. Beware of the 'anecdotal' evaluation - you
    are expected to take a critical view and justify your argument.
    You should try to give evidence to support your evaluation: this could include the result of testing and user trials, feedback from clients, etc. Do not be afraid
    to discuss weaknesses: your evaluation will be assessed by its validity, regardless of the quality of the product. If your product is not software, you will need
    to be particularly careful in planning how it will be evaluated. Be sure that enough time is allowed for gathering necessary evidence: it is essential that this
    is thought about early in the project.
    •	An evaluation of the project process
    Every project report should have a session/chapter for the evaluation of the project process. This section is fully described in your marking scheme. The emphasis
    should be on the learning process and on how well you managed your project work. What have you learned, and what would you do differently in future? Achievement
    of relevant objectives should be assessed, so look at the objectives in your Terms of Reference and see which ones are relevant here and which are part of the
    product/findings evaluation. You can reflect on your project plan and suggest other plans that might have worked better. You may also be able to discuss legal,
    social, ethical, or professional issues that have arisen and comment on your handling of them.
}

\section{Project Process}
\todo{Project Process}

An unexpected issue during data import was the number of unique ingredients found which totalled ~200,000. This was worked
around by instead only including a more limited list of ingredients that would suffice to import a target of \todo{Target} of
the total dataset. This led to \todo{How many?} recipes being available for use.

The \codelisting{fraction.js} package used to parse ingredient amounts could not be imported at first with an error message
stating that \enquote*{The current file is a CommonJS module ... however, the referenced file is an ECMAScript module}.
This issue had previously been reported by another user (\href{https://github.com/rawify/Fraction.js/issues/70}{https://github.com/rawify/Fraction.js/issues/70})
and was worked around by downgrading to version 4.3.4 of \codelisting{fraction.js} while the latest version at the time
of writing was 4.3.7.

The \codelisting{better-sqlite3} package declares row IDs as being \codelisting{number | bigint}
while \codelisting{openapi-typescript} generates \codelisting{number}, even if the type in the API
declaration lists the type as \codelisting{integer}. This initially required additional casting in every endpoint
that returns an ID. As a workaround, row IDs in the application were instead declared as \codelisting{number}
and an error is thrown if an insert produces a \codelisting{bigint} ID. As the maximum integer that can be safely stored as a number is
$(2^{53} - 1)$ \todo{source}, the chances of this happening were considered nonexistant.
